import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

# ğŸŒˆ Streamlit Page Config
st.set_page_config(
    page_title="Emoji Math Solver",
    page_icon="ğŸ§ ",
    layout="centered"
)

# ğŸ¨ Custom CSS Styling
st.markdown("""
    <style>
    .main {
        background-color: #fdfdfd;
    }
    .stTextArea textarea {
        font-size: 18px;
        line-height: 1.6;
    }
    .stButton button {
        background-color: #F63366;
        color: white;
        font-size: 18px;
        padding: 0.6em 1.2em;
        border-radius: 8px;
        margin-top: 10px;
    }
    .stButton button:hover {
        background-color: #e10050;
        color: white;
    }
    .emoji-title {
        font-size: 40px;
        text-align: center;
        margin-bottom: 0.2em;
    }
    .emoji-subtitle {
        font-size: 18px;
        text-align: center;
        color: #555;
        margin-bottom: 2em;
    }
    </style>
""", unsafe_allow_html=True)

# ğŸ§  App Header
st.markdown('<div class="emoji-title">ğŸ§  Emoji Math Solver</div>', unsafe_allow_html=True)
st.markdown('<div class="emoji-subtitle">AI-powered fun for emoji-based math riddles! ğŸ¤–â•ğŸâ—ğŸš—</div>', unsafe_allow_html=True)

# ğŸ“¦ Load model + tokenizer
with st.spinner("ğŸ”„ Loading model from Hugging Face... please wait"):
    tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
    model = AutoModelForCausalLM.from_pretrained("hassanhaseen/emoji-math-distilgpt2")
    generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# âœï¸ User Input
prompt = st.text_area(
    "ğŸ“ Enter your Emoji Math Problem below (must start with `Problem:`):",
    value="Problem: ğŸ + ğŸ + ğŸ = 15",
    height=150
)

# ğŸ§  Solve Button
if st.button("ğŸ§® Solve My Emoji Problem"):
    if not prompt.strip().lower().startswith("problem:"):
        st.error("âš ï¸ Please make sure your input starts with `Problem:`")
    else:
        with st.spinner("ğŸ” Thinking... solving your problem!"):
            result = generator(
                prompt,
                max_length=128,
                num_return_sequences=1,
                do_sample=True,
                truncation=True,
                pad_token_id=tokenizer.eos_token_id
            )
            full_output = result[0]["generated_text"]
            if "Solution:" in full_output:
                solution = full_output.split("Solution:")[-1].strip()
            else:
                solution = "âš ï¸ Hmm... I couldnâ€™t detect a solution. Try a different input?"

        # âœ… Display Result
        st.success("âœ… Solution Found!")
        st.markdown(f"### ğŸ§¾ `{solution}`")

# ğŸ‘£ Footer
st.markdown("""
---
Made with â¤ï¸ by [Hassan Haseen](https://github.com/hassanhaseen)  
Built using ğŸ¤— Transformers and deployed via ğŸš€ Streamlit Cloud
""")
