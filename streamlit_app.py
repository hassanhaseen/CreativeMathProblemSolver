import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

st.set_page_config(page_title="Creative Math Problem Solver", page_icon="üßÆ")

st.title("üß† Creative Math Problem Solver")
st.caption("Generate creative solutions for emoji math problems using TinyLlama!")

# ‚úÖ Cache the model and tokenizer loading for performance
@st.cache_resource(show_spinner="Loading model... (‚è≥)")
def load_model():
    # Model name (merged fine-tuned model)
    model_name = "hassanhaseen/tinyllama-emoji-math-merged"

    # ‚úÖ Use base tokenizer (assuming no added tokens)
    tokenizer = AutoTokenizer.from_pretrained("TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    # ‚úÖ Load the fine-tuned model
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype="auto",   # Auto-detects CPU/GPU dtype
        device_map="auto"     # Automatically places on available device
    )

    # ‚úÖ Create text generation pipeline
    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=100,   # Limit response length
        temperature=0.5,      # Creativity level (adjust if needed)
        top_p=0.95            # Nucleus sampling for diversity
    )
    return pipe

# ‚úÖ Load model
pipe = load_model()
st.success("‚úÖ Model Loaded Successfully!")

# ‚úÖ User input for math problem
user_input = st.text_area("üî¢ Enter an emoji math problem:", height=150)

if st.button("üí° Generate Solution"):
    if user_input.strip() == "":
        st.warning("‚ö†Ô∏è Please enter a math problem!")
    else:
        # ‚úÖ Format the prompt (matching fine-tuned training format)
        prompt = f"<|user|>\n{user_input}\n<|assistant|>\n"

        # ‚úÖ Generate response
        with st.spinner("Generating creative solution..."):
            response = pipe(prompt)

        # ‚úÖ Extract and display response
        answer = response[0]["generated_text"].split("<|assistant|>\n")[-1].strip()
        st.subheader("‚ú® Solution")
        st.write(answer)

st.caption("Made with ‚ù§Ô∏è using TinyLlama")
